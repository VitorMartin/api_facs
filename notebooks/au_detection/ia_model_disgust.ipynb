{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "908db170-2219-4a4c-9dc0-e0c6ef83cfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.utils import img_to_array\n",
    "from keras.utils.image_utils import smart_resize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f'Python: {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdac63b-febf-47ca-b258-878a7402c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a26b555-4003-4294-891f-a69ef5066c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with pre trained model \n",
    "\n",
    "#base_model = MobileNet(input_shape=(224, 224, 3), include_top=False)\n",
    "base_model = MobileNet(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(units=2 , activation='softmax')(x)\n",
    "\n",
    "# creating our model.\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2616ac31-9f8e-485c-9395-85d719fdb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=categorical_crossentropy , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d63a896a-3533-44d5-84f0-ed6b8681b3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = []\n",
    "directory_template = './data/images/images/train/$session$/'\n",
    "for session in os.listdir('./data/images/images/train'):\n",
    "    # Find XML filename\n",
    "    directory = directory_template.replace('$session$', session)\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    for file in files:\n",
    "        # Load JPG filename\n",
    "        jpg_filename = directory + file\n",
    "        \n",
    "        emotion_dict = {\n",
    "            'emotion': session,\n",
    "            'img': jpg_filename\n",
    "        }\n",
    "        sessions.append(emotion_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5630f906-232f-476c-8eba-9b848f83dceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           emotion                                           img  aus\n",
       "session                                                             \n",
       "0           angry        ./data/images/images/train/angry/0.jpg    0\n",
       "1           angry        ./data/images/images/train/angry/1.jpg    0\n",
       "2           angry       ./data/images/images/train/angry/10.jpg    0\n",
       "3           angry    ./data/images/images/train/angry/10002.jpg    0\n",
       "4           angry    ./data/images/images/train/angry/10016.jpg    0\n",
       "...           ...                                           ...  ...\n",
       "28816    surprise  ./data/images/images/train/surprise/9969.jpg    0\n",
       "28817    surprise  ./data/images/images/train/surprise/9985.jpg    0\n",
       "28818    surprise  ./data/images/images/train/surprise/9990.jpg    0\n",
       "28819    surprise  ./data/images/images/train/surprise/9992.jpg    0\n",
       "28820    surprise  ./data/images/images/train/surprise/9996.jpg    0\n",
       "\n",
       "[28821 rows x 3 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sessions = pd.DataFrame(sessions)\n",
    "df_sessions.index.rename('session', inplace=True)\n",
    "df_sessions[\"aus\"] = 0\n",
    "df_sessions.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9974fbc-f848-42f7-bdc2-e1b1d0e2e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_aus = pd.read_excel('data/aus.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9323b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anger = df_sessions.loc[lambda df: df['emotion'] == \"angry\"].reset_index()\n",
    "df_disgust = df_sessions.loc[lambda df: df['emotion'] == \"disgust\"].reset_index()\n",
    "df_happy = df_sessions.loc[lambda df: df['emotion'] == \"happy\"].reset_index()\n",
    "df_fear = df_sessions.loc[lambda df: df['emotion'] == \"fear\"].reset_index()\n",
    "df_surprise = df_sessions.loc[lambda df: df['emotion'] == \"surprise\"].reset_index()\n",
    "df_sadness = df_sessions.loc[lambda df: df['emotion'] == \"sad\"].reset_index()\n",
    "df_neutral = df_sessions.loc[lambda df: df['emotion'] == \"neutral\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c45982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodol\\AppData\\Local\\Temp\\ipykernel_9968\\3691740048.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_disgust[\"aus\"][i] = random_num\n",
      "C:\\Users\\rodol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list_anger = [\"4,5,7,17,23\", \"4,5,7,17,24\"]\n",
    "list_disgust = [\"9,17\", \"10, 17\"]\n",
    "list_sadness = [\"1,4,11,15,54,64\",\"1,4,15\",\"6,15,54,64\",\"11,17\",\"1,4,15,17\"]\n",
    "list_fear = [\"1,2,4,5\",\"1,2,4,5,25\"]\n",
    "list_surprise=[\"1,2,5,26\", \"1,2,26\"]\n",
    "list_happy = [\"6,12\"]\n",
    "list_neutral = [\"0\"]\n",
    "\n",
    "#for i in range(len(df_anger.values)):\n",
    "#      rand_idx = random.randrange(len(list_anger))\n",
    "#      random_num = list_anger[rand_idx]\n",
    "\n",
    "#      df_anger[\"aus\"][i] = random_num\n",
    "\n",
    "# i = 0\n",
    "for i in range(len(df_disgust.values)):\n",
    "     rand_idx = random.randrange(len(list_disgust))\n",
    "     random_num = list_disgust[rand_idx]\n",
    "\n",
    "     df_disgust[\"aus\"][i] = random_num\n",
    "\n",
    "# i = 0\n",
    "# for i in range(len(df_sadness.values)):\n",
    "#     rand_idx = random.randrange(len(list_sadness))\n",
    "#     random_num = list_sadness[rand_idx]\n",
    "\n",
    "#     df_sadness[\"aus\"][i] = random_num\n",
    "\n",
    "# i = 0\n",
    "# for i in range(len(df_fear.values)):\n",
    "#     rand_idx = random.randrange(len(list_fear))\n",
    "#     random_num = list_fear[rand_idx]\n",
    "\n",
    "#     df_fear[\"aus\"][i] = random_num\n",
    "\n",
    "# i = 0\n",
    "# for i in range(len(df_surprise.values)):\n",
    "#      rand_idx = random.randrange(len(list_surprise))\n",
    "#      random_num = list_surprise[rand_idx]\n",
    "\n",
    "#      df_surprise[\"aus\"][i] = random_num\n",
    "\n",
    "\n",
    "# df_anger[\"aus\"] = list_anger[2]\n",
    "# df_disgust[\"aus\"] = list_disgust[0]\n",
    "# df_sadness[\"aus\"] = list_sadness[0]\n",
    "# df_fear[\"aus\"] = list_fear[0]\n",
    "# df_surprise[\"aus\"] = list_surprise[0]\n",
    "# df_happy[\"aus\"] = list_happy[0]\n",
    "# df_neutral[\"aus\" ] = list_neutral[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb00a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_modelo = pd.concat([df_anger])\n",
    "df_disgust.to_csv(\"base_aus_disgust.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "367b8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modelo = pd.read_csv(\"base_aus_disgust.csv\")\n",
    "df_modelo = df_modelo.drop(columns=[\"Unnamed: 0\", \"session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d29c105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>img</th>\n",
       "      <th>aus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/14652.jpg</td>\n",
       "      <td>9,17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/19911.jpg</td>\n",
       "      <td>9,17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/13551.jpg</td>\n",
       "      <td>9,17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/7313.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/15780.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/8379.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/9159.jpg</td>\n",
       "      <td>9,17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/27771.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/11971.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>disgust</td>\n",
       "      <td>./data/images/images/train/disgust/13458.jpg</td>\n",
       "      <td>10, 17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                           img     aus\n",
       "59   disgust  ./data/images/images/train/disgust/14652.jpg    9,17\n",
       "141  disgust  ./data/images/images/train/disgust/19911.jpg    9,17\n",
       "49   disgust  ./data/images/images/train/disgust/13551.jpg    9,17\n",
       "391  disgust   ./data/images/images/train/disgust/7313.jpg  10, 17\n",
       "76   disgust  ./data/images/images/train/disgust/15780.jpg  10, 17\n",
       "..       ...                                           ...     ...\n",
       "405  disgust   ./data/images/images/train/disgust/8379.jpg  10, 17\n",
       "420  disgust   ./data/images/images/train/disgust/9159.jpg    9,17\n",
       "238  disgust  ./data/images/images/train/disgust/27771.jpg  10, 17\n",
       "26   disgust  ./data/images/images/train/disgust/11971.jpg  10, 17\n",
       "48   disgust  ./data/images/images/train/disgust/13458.jpg  10, 17\n",
       "\n",
       "[305 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_modelo, test_size=0.3)\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be12063-4f60-41cb-a603-01016ee67c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 305 validated image filenames belonging to 2 classes.\n",
      "Found 131 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    zoom_range = 0.2, \n",
    "    shear_range = 0.2, \n",
    "    horizontal_flip=True, \n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_dataframe(\n",
    "    dataframe = pd.concat([train]).sample(frac=1),\n",
    "    directory=\".\",\n",
    "    x_col = \"img\",\n",
    "    y_col = \"aus\",\n",
    "    subset = \"training\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (48,48)\n",
    ")\n",
    "\n",
    "test_data = train_datagen.flow_from_dataframe(\n",
    "    dataframe = pd.concat([test]).sample(frac=1),\n",
    "    directory=\".\",\n",
    "    x_col = \"img\",\n",
    "    y_col = \"aus\",\n",
    "    subset = \"training\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    class_mode = \"categorical\",\n",
    "    target_size = (48,48)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a6a8d0f-99a5-4b15-be3e-ff61c1014198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5082WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 5s 348ms/step - loss: 0.6933 - accuracy: 0.5082 - val_loss: 0.6927 - val_accuracy: 0.5420\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.6931 - accuracy: 0.5082\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.6931 - accuracy: 0.5082\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 0.6932 - accuracy: 0.5082\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.6933 - accuracy: 0.5082\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.6931 - accuracy: 0.5082\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 1s 47ms/step - loss: 0.6929 - accuracy: 0.5082\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.6929 - accuracy: 0.5082\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.6929 - accuracy: 0.5082\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 1s 63ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6931 - accuracy: 0.5082\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 0.6929 - accuracy: 0.5082\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 1s 47ms/step - loss: 0.6930 - accuracy: 0.5082\n",
      "\n",
      "Accuracy: max_acc = 50.82%\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=30,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=8,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='./results/model_aus_disgust.h5',\n",
    "            save_best_only=True,\n",
    "            monitor=\"accuracy\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print()\n",
    "max_acc = max(hist.history['accuracy']) * 100\n",
    "print(f'Accuracy: {max_acc = :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8626785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 641ms/step\n",
      "10, 17: 51.3%\n"
     ]
    }
   ],
   "source": [
    "labels = np.sort(df_modelo['aus'].unique())\n",
    "img_cv = cv.imread('./data/images/images/validation/disgust/533.jpg', cv.IMREAD_COLOR)\n",
    "img_keras = img_to_array(img_cv)\n",
    "img_keras = np.expand_dims(img_keras, axis=0)\n",
    "img_keras = smart_resize(img_keras, (224, 224))\n",
    "prediction = model.predict(img_keras)[0]\n",
    "mean = prediction.mean()\n",
    "std = prediction.std()\n",
    "prediction_idx = np.argmax(prediction)\n",
    "prediction_label = labels[prediction_idx]\n",
    "prediction_prob = prediction[prediction_idx]\n",
    "\n",
    "print(f'{prediction_label}: {round(prediction_prob * 100, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bac574fe11901c98da7470beb09037204aaaea101993e5af58b068248c4f83d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
